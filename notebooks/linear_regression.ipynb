{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "\n",
    "Linear Regression is a supervised learning algorithm that models the relationship between a dependent variable `y` and one or more independent variables `X` by fitting a straight line to the data.\n",
    "\n",
    "The equation for simple linear regression is:\n",
    "\n",
    "y = wX + b\n",
    "\n",
    "where:\n",
    "\n",
    "* `w` is the weight (slope)\n",
    "* `b` is the bias (intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True weights: [7.69519481 1.22667439]\n",
      "True bias: -2.129393249318823\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_linear_data(n_samples=100, n_features=1, noise_variance=1.0):\n",
    "    # Generate random features\n",
    "    X = np.random.uniform(0, 100, size=(n_samples, n_features))\n",
    "\n",
    "    # Define true weights and bias\n",
    "    true_weights = np.random.uniform(1, 10, size=n_features)\n",
    "    true_bias = np.random.uniform(-5, 5)\n",
    "\n",
    "    # Calculate the target variable with some noise\n",
    "    noise = np.random.normal(0, noise_variance, size=n_samples)\n",
    "    y = X @ true_weights + true_bias + noise\n",
    "\n",
    "    return X, y, true_weights, true_bias\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y, true_weights, true_bias = generate_linear_data(n_samples=100, n_features=2, noise_variance=1.0)\n",
    "\n",
    "# Select the first feature for plotting\n",
    "X_plot = X[:, 0]  # Select the first feature\n",
    "\n",
    "# Plot the generated data\n",
    "plt.scatter(X_plot, y, color='blue', label='Data points')\n",
    "plt.xlabel('X (Feature 1)')\n",
    "plt.ylabel('y')\n",
    "plt.title('Generated Linear Data')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Display true parameters\n",
    "print(\"True weights:\", true_weights)\n",
    "print(\"True bias:\", true_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, lr=0.0001, n_iters=10000):  # Adjusted learning rate\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Feature scaling\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(n_features)  # Initialized to zero\n",
    "        self.bias = 0\n",
    "        \n",
    "        tol = 1e-5\n",
    "        prev_loss = float('inf')  # Start with a high loss for comparison\n",
    "        \n",
    "        for i in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            \n",
    "            # Calculate gradients\n",
    "            dw = (1/n_samples) * (np.dot(X.T, (y_pred - y)))\n",
    "            db = (1/n_samples) * (np.sum(y_pred - y))\n",
    "            \n",
    "            # Update weights and bias\n",
    "            self.weights -= (self.lr * dw)\n",
    "            self.bias -= (self.lr * db)\n",
    "            \n",
    "            # Calculate current loss\n",
    "            current_loss = np.mean(np.square(y_pred - y))\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}: Loss = {current_loss}\")  # Print loss\n",
    "            \n",
    "            # Check for convergence\n",
    "            if abs(current_loss - prev_loss) < tol:\n",
    "                break\n",
    "            \n",
    "            prev_loss = current_loss\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 224647.97508372567\n",
      "Iteration 100: Loss = 220211.07182141687\n",
      "Iteration 200: Loss = 215861.83782998883\n",
      "Iteration 300: Loss = 211598.54009879762\n",
      "Iteration 400: Loss = 207419.47988928205\n",
      "Iteration 500: Loss = 203322.99205690972\n",
      "Iteration 600: Loss = 199307.44438654368\n",
      "Iteration 700: Loss = 195371.2369409629\n",
      "Iteration 800: Loss = 191512.80142227918\n",
      "Iteration 900: Loss = 187730.60054599095\n",
      "Iteration 1000: Loss = 184023.12742742748\n",
      "Iteration 1100: Loss = 180388.90498033556\n",
      "Iteration 1200: Loss = 176826.48532736977\n",
      "Iteration 1300: Loss = 173334.44922225003\n",
      "Iteration 1400: Loss = 169911.4054833552\n",
      "Iteration 1500: Loss = 166555.9904385273\n",
      "Iteration 1600: Loss = 163266.86738086297\n",
      "Iteration 1700: Loss = 160042.7260352754\n",
      "Iteration 1800: Loss = 156882.28203561401\n",
      "Iteration 1900: Loss = 153784.27641213176\n",
      "Iteration 2000: Loss = 150747.47508909568\n",
      "Iteration 2100: Loss = 147770.6683923404\n",
      "Iteration 2200: Loss = 144852.67056656632\n",
      "Iteration 2300: Loss = 141992.31930219146\n",
      "Iteration 2400: Loss = 139188.47527156607\n",
      "Iteration 2500: Loss = 136440.02167436562\n",
      "Iteration 2600: Loss = 133745.86379198034\n",
      "Iteration 2700: Loss = 131104.9285507228\n",
      "Iteration 2800: Loss = 128516.1640936796\n",
      "Iteration 2900: Loss = 125978.53936103506\n",
      "Iteration 3000: Loss = 123491.04367870055\n",
      "Iteration 3100: Loss = 121052.68635508358\n",
      "Iteration 3200: Loss = 118662.49628583672\n",
      "Iteration 3300: Loss = 116319.5215664276\n",
      "Iteration 3400: Loss = 114022.82911237527\n",
      "Iteration 3500: Loss = 111771.50428700181\n",
      "Iteration 3600: Loss = 109564.65053654919\n",
      "Iteration 3700: Loss = 107401.3890325168\n",
      "Iteration 3800: Loss = 105280.85832107638\n",
      "Iteration 3900: Loss = 103202.21397942325\n",
      "Iteration 4000: Loss = 101164.62827892805\n",
      "Iteration 4100: Loss = 99167.28985495359\n",
      "Iteration 4200: Loss = 97209.4033832048\n",
      "Iteration 4300: Loss = 95290.18926248259\n",
      "Iteration 4400: Loss = 93408.88330371436\n",
      "Iteration 4500: Loss = 91564.73642513914\n",
      "Iteration 4600: Loss = 89757.01435352184\n",
      "Iteration 4700: Loss = 87984.99733128006\n",
      "Iteration 4800: Loss = 86247.97982940596\n",
      "Iteration 4900: Loss = 84545.27026606769\n",
      "Iteration 5000: Loss = 82876.19073077828\n",
      "Iteration 5100: Loss = 81240.07671402245\n",
      "Iteration 5200: Loss = 79636.27684223215\n",
      "Iteration 5300: Loss = 78064.15261800615\n",
      "Iteration 5400: Loss = 76523.0781654689\n",
      "Iteration 5500: Loss = 75012.43998066742\n",
      "Iteration 5600: Loss = 73531.63668690676\n",
      "Iteration 5700: Loss = 72080.07879492526\n",
      "Iteration 5800: Loss = 70657.1884678155\n",
      "Iteration 5900: Loss = 69262.39929059509\n",
      "Iteration 6000: Loss = 67895.15604433678\n",
      "Iteration 6100: Loss = 66554.9144847668\n",
      "Iteration 6200: Loss = 65241.141125243244\n",
      "Iteration 6300: Loss = 63953.31302402825\n",
      "Iteration 6400: Loss = 62690.917575767904\n",
      "Iteration 6500: Loss = 61453.45230709815\n",
      "Iteration 6600: Loss = 60240.42467629313\n",
      "Iteration 6700: Loss = 59051.35187687788\n",
      "Iteration 6800: Loss = 57885.76064512539\n",
      "Iteration 6900: Loss = 56743.187071362205\n",
      "Iteration 7000: Loss = 55623.176415006754\n",
      "Iteration 7100: Loss = 54525.28292326626\n",
      "Iteration 7200: Loss = 53449.06965342033\n",
      "Iteration 7300: Loss = 52394.108298620115\n",
      "Iteration 7400: Loss = 51359.979017133366\n",
      "Iteration 7500: Loss = 50346.270264967025\n",
      "Iteration 7600: Loss = 49352.57863180094\n",
      "Iteration 7700: Loss = 48378.508680166786\n",
      "Iteration 7800: Loss = 47423.672787808304\n",
      "Iteration 7900: Loss = 46487.6909931596\n",
      "Iteration 8000: Loss = 45570.19084387988\n",
      "Iteration 8100: Loss = 44670.80724838448\n",
      "Iteration 8200: Loss = 43789.1823303121\n",
      "Iteration 8300: Loss = 42924.96528587135\n",
      "Iteration 8400: Loss = 42077.812244008186\n",
      "Iteration 8500: Loss = 41247.386129339764\n",
      "Iteration 8600: Loss = 40433.35652779901\n",
      "Iteration 8700: Loss = 39635.39955493663\n",
      "Iteration 8800: Loss = 38853.19772682824\n",
      "Iteration 8900: Loss = 38086.43983353463\n",
      "Iteration 9000: Loss = 37334.82081506466\n",
      "Iteration 9100: Loss = 36598.04163979181\n",
      "Iteration 9200: Loss = 35875.809185275\n",
      "Iteration 9300: Loss = 35167.8361214367\n",
      "Iteration 9400: Loss = 34473.840796051954\n",
      "Iteration 9500: Loss = 33793.54712250138\n",
      "Iteration 9600: Loss = 33126.68446974492\n",
      "Iteration 9700: Loss = 32472.987554471045\n",
      "Iteration 9800: Loss = 31832.196335379183\n",
      "Iteration 9900: Loss = 31204.055909553575\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([633.22152661, 297.84236781, 506.81689003,  94.24994021,\n",
       "        509.88756634]),\n",
       " array([11445.50695444,  5546.86585643,  9089.57945141,  1895.88301597,\n",
       "         9320.20755947]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization Techniques\n",
    "\n",
    "#### L1 Regularization (Lasso)\n",
    "Adds the sum of absolute values of weights to the loss function. Useful for feature selection, as it forces some weights to be exactly zero.\n",
    "\n",
    "#### L2 Regularization (Ridge)\n",
    "Adds the sum of squared weights to the loss function. Helps with preventing overfitting by shrinking the weights.\n",
    "\n",
    "#### Elastic Net\n",
    "A combination of L1 and L2 regularization. Balances between feature selection and shrinking coefficients.\n",
    "\n",
    "#### Loss Functions\n",
    "\n",
    "- **L2 Regularization (Ridge)**:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\text{MSE} + \\lambda \\sum w_i^2\n",
    "$$\n",
    "\n",
    "- **L1 Regularization (Lasso)**:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\text{MSE} + \\lambda \\sum |w_i|\n",
    "$$\n",
    "\n",
    "Regularization in linear regression is applied in the following scenarios:\n",
    "\n",
    "- Overfitting: When the model performs well on training data but poorly on test data, it indicates that the model is overfitting by capturing noise and irrelevant patterns in the data. Regularization helps by reducing the magnitude of the model coefficients, making the model less sensitive to fluctuations in the data and improving generalization.\n",
    "\n",
    "- Multicollinearity: When features are highly correlated, multicollinearity can lead to instability in the model (large swings in coefficients). Regularization helps by shrinking the coefficients, thus reducing variance and stabilizing the model's predictions in the presence of collinear features.\n",
    "\n",
    "- High-dimensional data: When the number of features is large compared to the number of samples, regularization is essential. High-dimensional models tend to overfit the data, and regularization constrains the model by penalizing large coefficients, improving performance on unseen data.\n",
    "\n",
    "- Feature Selection: In situations where many features are irrelevant, L1 regularization (Lasso) can be applied to perform automatic feature selection by shrinking some coefficients to exactly zero, effectively removing those features from the model.\n",
    "\n",
    "#### Best Use Case for Linear Regression\n",
    "\n",
    "- **Use Case**: Predicting continuous outcomes like house prices, stock prices, or any application where the relationship between the independent variables and the dependent variable is linear or approximately linear.\n",
    "\n",
    "- **Best Data**: Data where features have a linear relationship with the target variable.\n",
    "\n",
    "When to Avoid Regularization?\n",
    "- Underfitting: If the model is too simple and already underfitting the data (i.e., it is not capturing the underlying patterns), applying regularization can worsen the problem by overly shrinking the coefficients.\n",
    "- Sufficiently Small Data and Few Features: If you have a small number of features and enough data to capture relationships, regularization might not be necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring Correlation Between Features in a Dataset\n",
    "\n",
    "#### 1. Correlation Between Two Features\n",
    "\n",
    "To measure the correlation between two numerical features, the most common metrics are **Pearson’s Correlation Coefficient**, **Spearman’s Rank Correlation**, and **Kendall’s Tau**.\n",
    "\n",
    "#### **Pearson's Correlation Coefficient**\n",
    "Pearson’s correlation measures the linear relationship between two variables. It returns a value between -1 and 1:\n",
    "- +1 indicates a perfect positive correlation,\n",
    "- -1 indicates a perfect negative correlation,\n",
    "- 0 means no correlation.\n",
    "\n",
    "#### Formula:\n",
    "**Pearson Correlation Coefficient (r):**\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum (X_i - \\bar{X})^2 \\sum (Y_i - \\bar{Y})^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- `X_i` and `Y_i` are the feature values,\n",
    "- `\\bar{X}` and `\\bar{Y}` are the means of the features.\n",
    "\n",
    "#### **Example using NumPy**:\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X and Y are two numpy arrays\n",
    "correlation = np.corrcoef(X, Y)[0, 1]\n",
    "print(correlation)\n",
    "\n",
    "# Assuming df is a pandas DataFrame\n",
    "correlation = df['feature1'].corr(df['feature2'])\n",
    "print(correlation)\n",
    "```\n",
    "\n",
    "#### **Spearman’s Rank Correlation**\n",
    "Spearman's rank correlation assesses how well the relationship between two variables can be described using a monotonic function. This is useful for non-linear but monotonic relationships.\n",
    "\n",
    "```python\n",
    "correlation = df['feature1'].corr(df['feature2'], method='spearman')\n",
    "```\n",
    "\n",
    "#### **Kendall’s Tau**\n",
    "Kendall's Tau is used for ordinal data or small datasets, and it measures the correspondence between the rankings of two variables.\n",
    "\n",
    "```python\n",
    "correlation = df['feature1'].corr(df['feature2'], method='kendall')\n",
    "```\n",
    "\n",
    "#### 2. Correlation Between Multiple Features\n",
    "To measure correlation between multiple features, you can compute pairwise correlations between all features and display them in a correlation matrix.\n",
    "\n",
    "Using Pandas to Compute a Correlation Matrix:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is a DataFrame with several numerical features\n",
    "correlation_matrix = df.corr(method='pearson')  # or 'spearman', 'kendall'\n",
    "print(correlation_matrix)\n",
    "```\n",
    "\n",
    "This will generate a matrix where:\n",
    "\n",
    "- Each row and column represents a feature.\n",
    "- Each cell contains the correlation between two features.\n",
    "\n",
    "#### Visualizing the Correlation Matrix:\n",
    "You can use seaborn to visualize the correlation matrix as a heatmap.\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This will generate a heatmap where colors represent the strength and direction of correlations between the features.\n",
    "\n",
    "#### 3. Interpretation of Correlation Values\n",
    "Positive correlation (closer to 1): As one feature increases, the other tends to increase.\n",
    "Negative correlation (closer to -1): As one feature increases, the other tends to decrease.\n",
    "No correlation (around 0): There is no linear relationship between the features.\n",
    "\n",
    "#### Summary\n",
    "For two features, use np.corrcoef() or DataFrame.corr() with methods like Pearson, Spearman, or Kendall to compute the correlation.\n",
    "For multiple features, use DataFrame.corr() to compute a correlation matrix and visualize it with a heatmap for easy interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity\n",
    "\n",
    "**Multicollinearity** occurs when two or more independent variables in a regression model are highly correlated, meaning that one can be linearly predicted from the others with a substantial degree of accuracy. This situation makes it difficult to isolate the effect of each independent variable on the dependent variable because they provide redundant information.\n",
    "\n",
    "In linear regression, multicollinearity can lead to:\n",
    "\n",
    "Unstable coefficients: Regression coefficients might change significantly with small changes in the model.\n",
    "Inflated standard errors: Making hypothesis testing (t-tests) unreliable.\n",
    "Difficulty in interpreting the model: It's hard to determine the contribution of each independent variable.\n",
    "Common methods to detect multicollinearity:\n",
    "Variance Inflation Factor (VIF): Measures how much the variance of a regression coefficient is inflated due to multicollinearity.\n",
    "Condition Index: Assesses the dependency among the variables.\n",
    "\n",
    "#### Variance Inflation Factor (VIF) and Condition Index\n",
    "\n",
    "**Variance Inflation Factor (VIF)** quantifies how much the variance of a regression coefficient is inflated due to multicollinearity. It is calculated for each independent variable.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$VIF_i = \\frac{1}{1 - R_i^2}$$\n",
    "\n",
    "where `R_i^2` is the R-squared value obtained by regressing the `i`-th variable on all other independent variables.\n",
    "\n",
    "* **Low VIF (< 5):** Low multicollinearity.\n",
    "* **High VIF (> 10):** Significant multicollinearity.\n",
    "\n",
    "**Condition Index (CI)**\n",
    "\n",
    "Condition index assesses the dependency between independent variables using the eigenvalues of the matrix `X^TX`.\n",
    "\n",
    "**Formula:**\n",
    "$$CI = \\frac{\\text{largest eigenvalue}}{\\text{smallest eigenvalue}}$$\n",
    "\n",
    "* **Low CI (< 10):** Little multicollinearity.\n",
    "* **High CI (> 30):** Severe multicollinearity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Fit of a Linear Regression Model\n",
    "\n",
    "#### 1. Residual Plots\n",
    "\n",
    "Residual plots can help visualize the relationship between the residuals (the differences between observed and predicted values) and the independent variables or fitted values.\n",
    "\n",
    "* **If the relationship is linear:** The residuals should be randomly scattered around the horizontal axis (zero line).\n",
    "* **If a pattern is visible:** The relationship may be non-linear.\n",
    "\n",
    "**How to calculate:** Fit a linear regression model and plot residuals using libraries like matplotlib or seaborn.\n",
    "\n",
    "#### 2. Linearity Test in Linear Regression (ANOVA)\n",
    "\n",
    "Perform an analysis of variance (ANOVA) to test whether the linear model explains a significant amount of variance in the dependent variable.\n",
    "\n",
    "* **Low p-value:** A low p-value suggests a good fit.\n",
    "\n",
    "**How to calculate:** Use libraries like `statsmodels` in Python for ANOVA tests.\n",
    "\n",
    "#### 3. R-squared (Coefficient of Determination)\n",
    "\n",
    "R-squared measures the proportion of variance in the dependent variable explained by the independent variables.\n",
    "\n",
    "* **R-squared = 1:** Perfect linearity.\n",
    "* **R-squared = 0:** No linearity.\n",
    "\n",
    "**How to calculate:** Fit a linear regression model and get the R-squared score using `sklearn` or `statsmodels`.\n",
    "\n",
    "#### 4. Partial Regression Plots (Component-Plus-Residual Plot)\n",
    "\n",
    "These plots show the relationship between each independent variable and the dependent variable while controlling for other independent variables.\n",
    "\n",
    "**How to calculate:** Use `statsmodels` in Python.\n",
    "\n",
    "#### 5. Lack-of-Fit Test\n",
    "\n",
    "This statistical test can help determine if a linear model is appropriate.\n",
    "\n",
    "* **Small p-value:** Suggests a linear model is not appropriate.\n",
    "\n",
    "**How to calculate:** Use specialized libraries in R or Python with `scipy.stats`.\n",
    "\n",
    "#### 6. Linear Regression Coefficients\n",
    "\n",
    "Analyze the coefficients of the fitted linear regression model. If the independent variables are strongly related to the dependent variable, their coefficients should be significantly different from zero (based on p-values).\n",
    "\n",
    "**How to calculate:** Use linear regression models from `sklearn` or `statsmodels` in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Linear Regression Outputs: statsmodels vs. scikit-learn\n",
    "\n",
    "**statsmodels** and **scikit-learn (sklearn)** are both popular Python libraries for statistical modeling and machine learning, respectively. While they can both be used to perform linear regression, they provide different outputs and focus on different aspects of the modeling process. Here's a comparison of their outputs:\n",
    "\n",
    "#### 1. Basic Output\n",
    "\n",
    "* **statsmodels:**\n",
    "    - Provides a comprehensive summary, including coefficients, standard errors, t-values, p-values, R-squared, and confidence intervals.\n",
    "    - Ideal for users interested in statistical properties and hypothesis testing.\n",
    "\n",
    "* **scikit-learn:**\n",
    "    - Focuses on prediction and provides simpler output with coefficients, intercept, and R-squared.\n",
    "    - Suitable for machine learning applications where prediction is the primary goal.\n",
    "\n",
    "#### 2. Use Cases\n",
    "\n",
    "* **statsmodels:**\n",
    "    - Exploratory data analysis where understanding relationships and significance of predictors is crucial.\n",
    "    - Statistical inference and hypothesis testing.\n",
    "* **scikit-learn:**\n",
    "    - Predictive modeling and machine learning applications.\n",
    "    - Easier integration into machine learning pipelines and workflows.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "While both libraries can perform linear regression and provide the coefficients of the model, statsmodels offers a more detailed statistical analysis and diagnostic output, whereas scikit-learn is geared towards model fitting and prediction with a simpler output structure. Choose the library based on your specific needs, whether you prioritize statistical inference or predictive modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statsmodels Linear Regression Summary Output\n",
    "\n",
    "When you print the summary of a linear regression model fitted using statsmodels, it provides a comprehensive overview of the model's results. Below are the key components of the output, along with explanations of each term and its significance.\n",
    "\n",
    "#### Summary Output Components\n",
    "\n",
    "#### 1. Model Information\n",
    "- **Dep. Variable**: The dependent variable (response variable) for the regression model. This is the variable you are trying to predict.\n",
    "- **Model**: Indicates the type of model used (e.g., OLS for Ordinary Least Squares).\n",
    "- **Method**: The estimation method used to fit the model (e.g., Least Squares).\n",
    "- **Date**: The date when the model was fitted.\n",
    "- **Time**: The time when the model was fitted.\n",
    "- **No. Observations**: The total number of observations (data points) used in the model.\n",
    "- **Df Residuals**: Degrees of freedom of the residuals, calculated as the number of observations minus the number of parameters estimated.\n",
    "- **Df Model**: Degrees of freedom of the model, which is equal to the number of predictors (independent variables) in the model.\n",
    "\n",
    "#### 2. Statistical Measures\n",
    "- **R-squared**: A statistical measure that represents the proportion of the variance for the dependent variable that is explained by the independent variables in the model. Values range from 0 to 1, with higher values indicating a better fit.\n",
    "- **Adj. R-squared**: Adjusted R-squared, which adjusts the R-squared value based on the number of predictors in the model. This measure is useful for comparing models with different numbers of predictors.\n",
    "- **F-statistic**: A measure of the overall significance of the model. It tests whether at least one predictor variable has a non-zero coefficient. Higher values indicate a more significant model.\n",
    "- **Prob (F-statistic)**: The p-value associated with the F-statistic. A low p-value (typically < 0.05) indicates that the model is statistically significant.\n",
    "\n",
    "#### 3. Coefficients Table\n",
    "The coefficients table provides the following information for each predictor variable in the model:\n",
    "\n",
    "- **coef**: The estimated coefficient for each predictor variable, representing the change in the dependent variable for a one-unit change in the predictor variable, assuming all other variables are held constant.\n",
    "- **std err**: The standard error of the coefficient estimates, indicating the average distance that the estimated coefficients vary from the actual population value. Smaller values suggest more precise estimates.\n",
    "- **t**: The t-statistic, calculated as the coefficient divided by its standard error. It tests the null hypothesis that the coefficient is equal to zero (no effect).\n",
    "- **P>|t|**: The p-value associated with the t-statistic. A low p-value (typically < 0.05) indicates that the predictor variable is statistically significant in explaining the variation in the dependent variable.\n",
    "- **[0.025, 0.975]**: The 95% confidence interval for the coefficient, which provides a range of values that is likely to contain the true coefficient value. If this interval does not include zero, it suggests the predictor is statistically significant.\n",
    "\n",
    "#### 4. Additional Information\n",
    "- **Omnibus**: A test statistic for the normality of residuals. The null hypothesis is that the residuals are normally distributed. \n",
    "- **Prob(Omnibus)**: The p-value associated with the Omnibus test. A low value indicates the residuals may not be normally distributed.\n",
    "- **Skew**: The skewness of the residuals. A skewness of 0 indicates a symmetric distribution.\n",
    "- **Kurtosis**: A measure of the \"tailedness\" of the residuals' distribution. Higher values indicate more outliers.\n",
    "- **Cond. No.**: The condition number, which assesses the sensitivity of the model to small changes in the data. High values may indicate multicollinearity issues among predictor variables.\n",
    "\n",
    "#### Summary\n",
    "The statsmodels summary output provides a wealth of information about the fitted linear regression model, including details on model fit, significance of predictors, and diagnostic tests. Understanding these components is essential for interpreting the results and making informed decisions based on the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between R-squared and Adjusted R-squared\n",
    "\n",
    "#### R-squared (R²)\n",
    "- **Definition**: R-squared measures the proportion of the variance in the dependent variable that can be explained by the independent variables in the model. It indicates how well the model fits the data.\n",
    "- **Calculation**: R² is calculated as:\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- `SS_res` is the residual sum of squares (the sum of squared differences between observed and predicted values).\n",
    "- `SS_tot` is the total sum of squares (the sum of squared differences between observed values and the mean of the dependent variable).\n",
    "  \n",
    "- **Range**: R-squared values range from 0 to 1:\n",
    "  - **0**: Indicates that the model does not explain any of the variance in the dependent variable.\n",
    "  - **1**: Indicates that the model explains all the variance in the dependent variable.\n",
    "\n",
    "#### Adjusted R-squared (Adj. R²)\n",
    "- **Definition**: Adjusted R-squared modifies the R-squared value to account for the number of predictors in the model. It provides a more accurate measure of goodness-of-fit when multiple predictors are included, penalizing for the addition of irrelevant predictors.\n",
    "- **Calculation**: Adjusted R² is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Adj. } R^2 = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - p - 1} \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- `n` is the number of observations (data points).\n",
    "- `p` is the number of predictors in the model.\n",
    "  \n",
    "- **Range**: Adjusted R-squared values can be less than 0, but generally range from 0 to 1:\n",
    "  - **0**: Indicates that the model does not explain any of the variance in the dependent variable (similar to R-squared).\n",
    "  - **Negative values**: Indicate that the model is worse than simply using the mean of the dependent variable as a predictor.\n",
    "  - **Closer to 1**: Indicates a better fit after adjusting for the number of predictors.\n",
    "\n",
    "#### Summary\n",
    "- **R-squared** tends to increase with the addition of more predictors, regardless of their relevance.\n",
    "- **Adjusted R-squared** provides a more reliable measure of model fit by accounting for the number of predictors, making it a better choice for model comparison, especially when dealing with multiple regression models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion)\n",
    "\n",
    "## AIC (Akaike Information Criterion)\n",
    "- **Definition**: AIC is a metric used to compare the goodness-of-fit of different statistical models, balancing model fit and complexity.\n",
    "- **Formula**: \n",
    "\n",
    "**Akaike Information Criterion (AIC):**\n",
    "\n",
    "$$\n",
    "\\text{AIC} = 2k - 2\\ln(L)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- `k` is the number of parameters in the model.\n",
    "- `L` is the maximum likelihood of the model.\n",
    "\n",
    "- **Interpretation**: Lower AIC values indicate a better model. AIC penalizes models with more parameters to avoid overfitting.\n",
    "\n",
    "## BIC (Bayesian Information Criterion)\n",
    "- **Definition**: BIC is another model selection criterion similar to AIC, but with a stronger penalty for the number of parameters.\n",
    "- **Formula**: \n",
    "\n",
    "\n",
    "\n",
    "- **Interpretation**: Lower BIC values indicate a better model. BIC penalizes models with more parameters more heavily than AIC, favoring simpler models with fewer predictors.\n",
    "\n",
    "## Summary\n",
    "Both AIC and BIC are used to select the best model, with **AIC** being more lenient in adding parameters and **BIC** favoring simpler models, especially when the sample size is large.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
