{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of LSTM, GRU, RNN, and Transformer-based models, we'll use a publicly available dataset suitable for sequence prediction. The Air Quality UCI dataset is a good candidate, as it contains time series data on air quality measurements. The task will be to predict the air quality index (AQI) based on historical data.\n",
    "\n",
    "Overview of the Plan\n",
    "- Dataset Selection: Use the Air Quality UCI dataset.\n",
    "- Data Preprocessing: Prepare the data for each model.\n",
    "- Model Implementation: Implement RNN, GRU, LSTM, and Transformer models.\n",
    "- Training and Inference: Measure training time, inference time, and evaluation metrics.\n",
    "- Results Comparison: Compare the performance of each model.\n",
    "\n",
    "#### Dataset Selection\n",
    "We'll use the Air Quality UCI dataset, which can be downloaded from UCI Machine Learning Repository (https://archive.ics.uci.edu/dataset/360/air+quality). \n",
    "\n",
    "```bash\n",
    "pip install pandas numpy seaborn matplotlib\n",
    "```\n",
    "\n",
    "#### Data Preprocessing\n",
    "Hereâ€™s a quick script to preprocess the dataset and prepare it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "X_train shape: (7568, 10, 6)\n",
      "X_test shape: (1892, 10, 6)\n",
      "y_train shape: (7568,)\n",
      "y_test shape: (1892,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Define URL and download ZIP file\n",
    "url = \"https://archive.ics.uci.edu/static/public/360/air+quality.zip\"\n",
    "zip_file = \"air_quality.zip\"\n",
    "csv_file = \"AirQualityUCI.csv\"\n",
    "\n",
    "# Download the ZIP file\n",
    "response = requests.get(url)\n",
    "with open(zip_file, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extract the CSV file from the ZIP\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extract(csv_file)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(csv_file, sep=';')  # Use ';' as separator due to the dataset format\n",
    "\n",
    "# Data preprocessing\n",
    "# Keep only the relevant columns\n",
    "df = df.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7]]  # Adjust column indices as necessary\n",
    "df.columns = ['Date', 'Time', 'CO', 'C6H6', 'NOx', 'NO2', 'O3', 'T']\n",
    "\n",
    "# Replace periods with colons in the Time column\n",
    "df['Time'] = df['Time'].str.replace('.', ':', regex=False)\n",
    "\n",
    "# Combine Date and Time and convert to datetime\n",
    "df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], dayfirst=True)\n",
    "\n",
    "df = df.set_index('Datetime')\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df = df[['CO', 'C6H6', 'NOx', 'NO2', 'O3', 'T']]\n",
    "\n",
    "# Replace commas with periods for numeric conversion\n",
    "df = df.replace(',', '.', regex=True)\n",
    "\n",
    "# Convert columns to numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill missing values (interpolation)\n",
    "df = df.interpolate(method='linear')\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df.values)\n",
    "\n",
    "# Prepare sequences for time series forecasting\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), :])\n",
    "        y.append(data[i + time_step, 0])  # Predicting CO\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create datasets\n",
    "time_step = 10\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(\"Shapes of the datasets:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Models in TensorFlow and PyTorch\n",
    "Next, I will provide implementations for RNN, GRU, LSTM, and Transformer using both TensorFlow and PyTorch.\n",
    "\n",
    "#### TensorFlow Implementation\n",
    "RNN, GRU, LSTM, and Transformer in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, GRU, SimpleRNN, Dense, Dropout, Flatten, Input\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Dropout, Flatten, Input\n",
    "\n",
    "# Function to create RNN model\n",
    "def create_rnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Function to create GRU model\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Function to create LSTM model\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Function to create Transformer model\n",
    "def create_transformer_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Flatten()(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Prepare input shapes\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = np.mean((predictions - y_test.reshape(-1, 1)) ** 2)\n",
    "    return mse\n",
    "\n",
    "# Train and evaluate models in TensorFlow\n",
    "models_tf = {\n",
    "    \"RNN\": create_rnn_model(input_shape),\n",
    "    \"GRU\": create_gru_model(input_shape),\n",
    "    \"LSTM\": create_lstm_model(input_shape),\n",
    "    \"Transformer\": create_transformer_model((X_train.shape[1], X_train.shape[2])),\n",
    "}\n",
    "\n",
    "results_tf = {}\n",
    "for model_name, model in models_tf.items():\n",
    "    mse = train_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "    results_tf[model_name] = mse\n",
    "\n",
    "print(\"TensorFlow Model Results (MSE):\")\n",
    "print(results_tf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Implementation\n",
    "RNN, GRU, LSTM, and Transformer in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model Results:\n",
      "         Model  Training Time (s)  Average Inference Time (s)      RMSE\n",
      "0          RNN          19.172516                    0.069543  0.242882\n",
      "1          GRU         138.019992                    0.853577  0.261966\n",
      "2         LSTM         150.027126                    0.317735  0.258679\n",
      "3  Transformer           9.036658                    0.054682  0.185528\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, 50, batch_first=True)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last output\n",
    "        return out\n",
    "\n",
    "# Define the GRU Model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, 50, batch_first=True)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Define the LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, 50, batch_first=True)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Define a simple Transformer Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc_out = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.dropout(x, p=0.1, train=self.training)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.dropout(x, p=0.1, train=self.training)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return self.fc_out(x)\n",
    "\n",
    "# Function to train and evaluate models in PyTorch\n",
    "def train_and_evaluate_pytorch(model, X_train, y_train, X_test, y_test):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start_inference = time.time()\n",
    "        predictions = model(X_test_tensor)\n",
    "        inference_time = time.time() - start_inference\n",
    "\n",
    "    # Calculate RMSE\n",
    "    mse = criterion(predictions, torch.tensor(y_test, dtype=torch.float32).view(-1, 1)).item()\n",
    "    rmse = mse ** 0.5\n",
    "\n",
    "    return training_time, inference_time, rmse\n",
    "\n",
    "# Prepare input size for models\n",
    "input_size = X_train.shape[2]\n",
    "\n",
    "# Train and evaluate models in PyTorch\n",
    "models_pt = {\n",
    "    \"RNN\": RNNModel(input_size),\n",
    "    \"GRU\": GRUModel(input_size),\n",
    "    \"LSTM\": LSTMModel(input_size),\n",
    "    \"Transformer\": TransformerModel(input_size * time_step),  # Flatten for transformer\n",
    "}\n",
    "\n",
    "results_pt = []\n",
    "for model_name, model in models_pt.items():\n",
    "    training_time, inference_time, rmse = train_and_evaluate_pytorch(model, X_train, y_train, X_test, y_test)\n",
    "    results_pt.append({\n",
    "        'Model': model_name,\n",
    "        'Training Time (s)': training_time,\n",
    "        'Average Inference Time (s)': inference_time,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results_pt)\n",
    "\n",
    "# Display results\n",
    "print(\"PyTorch Model Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
