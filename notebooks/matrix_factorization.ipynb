{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Matrix Factorization?\n",
    "Matrix factorization is a collaborative filtering technique commonly used in recommendation systems. It decomposes a large matrix (such as a user-item interaction matrix) into the product of two smaller matrices. The objective is to represent the original matrix in terms of latent factors that capture the underlying patterns between users and items.\n",
    "\n",
    "For example, in a user-item matrix where each entry represents a rating or interaction between a user and an item, matrix factorization decomposes this matrix into:\n",
    "\n",
    "- User Matrix (U): Latent factors for users\n",
    "- Item Matrix (V): Latent factors for items\n",
    "\n",
    "The idea is that by multiplying the user and item matrices, you can approximate the original matrix, even for the missing values. This is often used for predicting user preferences or ratings for items they haven't interacted with.\n",
    "\n",
    "#### Where is Matrix Factorization Used?\n",
    "Matrix factorization is widely used in recommendation systems, especially in collaborative filtering. Key applications include:\n",
    "\n",
    "- Movie Recommendations: Predicting movies that a user may like based on their viewing history.\n",
    "- Music Recommendations: Suggesting songs or artists based on users’ listening habits.\n",
    "- E-commerce: Recommending products to users based on purchase history or browsing patterns.\n",
    "- Content Filtering: Filtering content on social media platforms based on user interests.\n",
    "\n",
    "#### Getting a Dataset in Python\n",
    "Let’s use the MovieLens dataset, a popular dataset for recommendation systems. The MovieLens dataset provides user ratings for movies, making it ideal for matrix factorization.\n",
    "\n",
    "You can download and load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-27 12:51:44--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: ‘ml-100k.zip’\n",
      "\n",
      "ml-100k.zip         100%[===================>]   4.70M  6.83MB/s    in 0.7s    \n",
      "\n",
      "2024-10-27 12:51:45 (6.83 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
      "\n",
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the MovieLens 100k dataset\n",
    "!wget -nc http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "\n",
    "# Read the ratings data\n",
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=column_names)\n",
    "ratings = ratings[['user_id', 'item_id', 'rating']]  # Drop timestamp for simplicity\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Matrix Factorization Model in Python\n",
    "Using Surprise library, which has a built-in implementation of matrix factorization (SVD), we can quickly set up a recommendation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Prepare data for Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "# Split data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Build and train the SVD model\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, the SVD model in the Surprise library by default breaks down the user-item matrix into 100 latent dimensions (also called factors). However, this number can be changed and optimized to improve model performance.\n",
    "\n",
    "#### Optimizing the Number of Latent Dimensions\n",
    "To find the optimal number of latent dimensions, you can use grid search or cross-validation. In Surprise, you can specify the n_factors parameter of the SVD class, which controls the number of latent factors. Here’s how to perform a grid search to optimize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.9357386532003883\n",
      "Best parameters: {'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Define a parameter grid for SVD\n",
    "param_grid = {'n_factors': [20, 50, 100, 150, 200]}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5)\n",
    "grid_search.fit(data)\n",
    "\n",
    "# Best score and parameters\n",
    "print(\"Best RMSE score:\", grid_search.best_score['rmse'])\n",
    "print(\"Best parameters:\", grid_search.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics\n",
    "For evaluating the recommendation model, consider these metrics:\n",
    "\n",
    "- Root Mean Square Error (RMSE): Measures the difference between predicted and actual ratings.\n",
    "- Mean Absolute Error (MAE): Similar to RMSE but measures absolute differences.\n",
    "- Precision@K and Recall@K: For top-K recommendations, measures the relevance of items in the top-K results.\n",
    "- Mean Average Precision (MAP): Measures the average precision at different levels of recall.\n",
    "\n",
    "#### Calculate RMSE as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9498076019628686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding RMSE in Recommendation Systems\n",
    "\n",
    "- Range of RMSE: RMSE (Root Mean Squared Error) ranges from 0 to ∞.\n",
    "- 0 represents perfect prediction (no error), while larger values indicate higher error between predictions and actual values.\n",
    "- In practical recommendation systems, a lower RMSE means the model's predictions are closer to actual user preferences.\n",
    "\n",
    "#### What’s a Good RMSE Value?\n",
    "\n",
    "- Good RMSE values depend on the dataset and industry standards. In movie recommendations, an RMSE between 0.8 to 1.0 is considered reasonable.\n",
    "- Bad RMSE values vary but generally, anything over 1.2 may indicate the model is struggling to capture user preferences accurately.\n",
    "- Benchmarking: RMSE alone isn’t always sufficient for determining a \"good\" model. It’s useful to benchmark against other models or baselines (e.g., a random or popular-item recommender) to gauge relative performance.\n",
    "\n",
    "#### Other Considerations with Matrix Factorization\n",
    "\n",
    "- Cold Start Problem: Matrix factorization struggles with new users or items that have little interaction data. Hybrid methods (combining matrix factorization with content-based features) can help mitigate this.\n",
    "- Implicit vs. Explicit Feedback: Matrix factorization is often designed for explicit feedback like ratings, but in real-world applications, implicit feedback (e.g., clicks or views) is more common. Extensions like Alternating Least Squares (ALS) for implicit feedback are often used.\n",
    "- Regularization: Regularization is key to prevent overfitting, as it helps the model generalize by penalizing large factor values.\n",
    "- Latent Factor Interpretation: Latent factors can sometimes be interpretable, e.g., representing genres in movies or price sensitivity in e-commerce. But interpretation is not guaranteed and often requires careful analysis.\n",
    "\n",
    "\n",
    "#### Generating a Rating or Score from User Actions in E-Commerce\n",
    "In e-commerce, we often don’t have explicit ratings. Instead, we can generate an implicit score based on user behavior and interaction data. Here’s how we can approximate a \"rating\" from different website events:\n",
    "\n",
    "- Assign Implicit Scores to User Actions:\n",
    "\n",
    "    - Page View: Indicates mild interest. Assign a lower score, e.g., 1.\n",
    "    - Click on Product: Stronger interest. Assign a score, e.g., 2.\n",
    "    - Add to Cart: Indicates high interest. Assign a score, e.g., 3.\n",
    "    - Purchase: Strongest signal. Assign a high score, e.g., 5.\n",
    "\n",
    "- Weight Different Actions:\n",
    "\n",
    "Combine these actions for each user-item pair. For example:\n",
    "```score = α × views + β × clicks + γ × add to cart + δ × purchase\n",
    "```\n",
    "\n",
    "where:\n",
    "- α, β, γ, δ are weights representing the relative importance of each action.\n",
    "- Adjust these weights based on what behaviors best predict purchase or user preference.\n",
    "\n",
    "- Time Decay:\n",
    "\n",
    "    - Apply time decay to make recent actions more influential. For example, if a user recently viewed an item, it’s more indicative of interest than a view from months ago.\n",
    "\n",
    "- Build an Interaction Matrix:\n",
    "\n",
    "    - With these scores, create an interaction matrix similar to a user-item rating matrix. Matrix factorization can then be applied to predict missing values in this implicit score matrix.\n",
    "\n",
    "- Event-Driven Modeling:\n",
    "\n",
    "    - Advanced e-commerce recommenders use event-driven scoring. For example, the model may update scores in real-time as a user interacts with items, adjusting recommendations dynamically.\n",
    "\n",
    "#### Example in Python for Implicit Ratings with Matrix Factorization\n",
    "Here’s an outline using the implicit library in Python for ALS on implicit feedback data:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "# Sample implicit feedback data\n",
    "data = {'user_id': [1, 2, 3, 1], 'item_id': [101, 101, 102, 103], 'action': ['view', 'add_to_cart', 'purchase', 'click']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Assign scores for each action\n",
    "score_map = {'view': 1, 'click': 2, 'add_to_cart': 3, 'purchase': 5}\n",
    "df['score'] = df['action'].map(score_map)\n",
    "\n",
    "# Create a sparse matrix for user-item interactions\n",
    "user_item_matrix = coo_matrix((df['score'], (df['user_id'], df['item_id'])))\n",
    "\n",
    "# Train ALS model\n",
    "model = AlternatingLeastSquares(factors=20, regularization=0.1)\n",
    "model.fit(user_item_matrix.T)\n",
    "```\n",
    "\n",
    "#### Evaluation Metrics for Implicit Feedback Models\n",
    "- Mean Average Precision at K (MAP@K): Measures precision of top-K recommendations.\n",
    "- Precision@K and Recall@K: Track how many relevant items are in the top-K results.\n",
    "- Normalized Discounted Cumulative Gain (NDCG): Measures ranking quality and prioritizes correct recommendations in the top positions.\n",
    "- Hit Rate: Measures how often a relevant item appears in recommendations.\n",
    "\n",
    "By combining implicit scoring techniques with matrix factorization or other recommendation algorithms, we can build effective recommendation systems in real-world e-commerce environments.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://www.youtube.com/embed/ZspR5PZemcs\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15971f640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# Embed the YouTube video\n",
    "IFrame('https://www.youtube.com/embed/ZspR5PZemcs', width=800, height=450)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video explains the concept of matrix factorization, a technique used in recommendation systems like Netflix to predict user ratings for items they haven't interacted with.\n",
    "\n",
    "#### Key points:\n",
    "\n",
    "- Implicit Ratings: In e-commerce, explicit ratings are often unavailable. Implicit ratings can be derived from user behavior (e.g., views, clicks, purchases).\n",
    "- Matrix Factorization: This technique decomposes a large user-item rating matrix into two smaller matrices: user features and item features.\n",
    "- Feature Engineering: Features can be explicit (e.g., genre, director) or latent (discovered through the factorization process).\n",
    "- Predicting Ratings: By multiplying the user and item feature matrices, we can predict ratings for unrated items.\n",
    "- Gradient Descent: This optimization algorithm is used to find the optimal values for the user and item features.\n",
    "- Benefits of Matrix Factorization:\n",
    "    - Improved storage efficiency\n",
    "    - Ability to handle sparse data\n",
    "    - Effective prediction of user preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
